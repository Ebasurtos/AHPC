{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqWYpQqjpyajeIp3mksRPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebasurtos/AHPC/blob/main/An%C3%A1lisis_de_Performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance_analysis_corrected.py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "class ParallelPerformanceModel:\n",
        "    \"\"\"Modelo teórico de performance para la ecuación de calor 2D paralela\"\"\"\n",
        "\n",
        "    def __init__(self, N_total, p, alpha=1e-6, beta=1e-9):\n",
        "        \"\"\"\n",
        "        N_total: puntos totales (N × N)\n",
        "        p: número de procesos\n",
        "        alpha: tiempo por operación de punto flotante (segundos)\n",
        "        beta: tiempo por byte de comunicación (segundos/byte)\n",
        "        \"\"\"\n",
        "        self.N = int(np.sqrt(N_total))\n",
        "        self.p = p\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def compute_serial_time(self):\n",
        "        \"\"\"Tiempo secuencial teórico\"\"\"\n",
        "        # Operaciones por celda por iteración: ~10 flops\n",
        "        flops_per_cell = 10\n",
        "        total_flops = self.N * self.N * flops_per_cell\n",
        "        return total_flops * self.alpha\n",
        "\n",
        "    def compute_parallel_time(self, iters=100):\n",
        "        \"\"\"Tiempo paralelo teórico por iteración\"\"\"\n",
        "        N_local = self.N / np.sqrt(self.p)\n",
        "\n",
        "        # Tiempo de cómputo\n",
        "        flops_per_cell = 10\n",
        "        comp_time = N_local * N_local * flops_per_cell * self.alpha\n",
        "\n",
        "        # Tiempo de comunicación (halos en 4 direcciones)\n",
        "        halo_size = N_local * 8  # 8 bytes por double\n",
        "        comm_time = 4 * (self.beta * halo_size)  # 4 vecinos\n",
        "\n",
        "        # Tiempo de sincronización (Allreduce)\n",
        "        sync_time = np.log2(self.p) * 100 * self.alpha\n",
        "\n",
        "        return (comp_time + comm_time + sync_time) * iters\n",
        "\n",
        "    def compute_speedup(self):\n",
        "        \"\"\"Speedup teórico\"\"\"\n",
        "        T_serial = self.compute_serial_time()\n",
        "        T_parallel = self.compute_parallel_time()\n",
        "        return T_serial / T_parallel\n",
        "\n",
        "    def compute_efficiency(self):\n",
        "        \"\"\"Eficiencia teórica\"\"\"\n",
        "        return self.compute_speedup() / self.p\n",
        "\n",
        "    def compute_scalability_limit(self):\n",
        "        \"\"\"Límite de escalabilidad (Gustafson's Law)\"\"\"\n",
        "        # Fórmula: S(p) = p + (1-p)*s, donde s es fracción secuencial\n",
        "        s = 0.01  # estimado del 1% secuencial\n",
        "        return self.p + (1 - self.p) * s\n",
        "\n",
        "def analyze_communication_pattern():\n",
        "    \"\"\"Analiza patrones de comunicación para diferentes topologías\"\"\"\n",
        "\n",
        "    topologies = ['1D Pipeline', '2D Mesh', '2D Torus', 'Hypercube']\n",
        "    p_values = [2**i for i in range(1, 7)]  # 2, 4, 8, 16, 32, 64\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for p in p_values:\n",
        "        # Comunicación para topología 2D Mesh (asumida en el código)\n",
        "        mesh_dim = int(np.sqrt(p))\n",
        "        if mesh_dim**2 == p:  # Cuadrado perfecto\n",
        "            # Cada proceso tiene 4 vecinos (excepto bordes)\n",
        "            avg_neighbors = 4 * (1 - 2/mesh_dim + 1/(mesh_dim**2))\n",
        "            comm_volume = 2 * avg_neighbors * 8  # 2 direcciones, 8 bytes\n",
        "\n",
        "            results.append({\n",
        "                'Processes': p,\n",
        "                'Topology': '2D Mesh',\n",
        "                'Diameter': 2*(mesh_dim-1),\n",
        "                'AvgDegree': avg_neighbors,\n",
        "                'BisectionWidth': mesh_dim,\n",
        "                'CommVolume': comm_volume\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def plot_scalability_analysis():\n",
        "    \"\"\"Genera análisis completo de escalabilidad\"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "    # 1. Strong Scaling\n",
        "    ax1 = plt.subplot(2, 3, 1)\n",
        "    N = 10000\n",
        "    p_values = np.arange(1, 65)\n",
        "\n",
        "    speedups_ideal = p_values\n",
        "    speedups_real = []\n",
        "\n",
        "    for p in p_values:\n",
        "        model = ParallelPerformanceModel(N, p)\n",
        "        speedups_real.append(model.compute_speedup())\n",
        "\n",
        "    ax1.plot(p_values, speedups_ideal, 'r--', label='Ideal', linewidth=2)\n",
        "    ax1.plot(p_values, speedups_real, 'b-', label='Real', linewidth=2)\n",
        "    ax1.fill_between(p_values, speedups_real, speedups_ideal, alpha=0.2, color='red')\n",
        "    ax1.set_xlabel('Number of Processes')\n",
        "    ax1.set_ylabel('Speedup')\n",
        "    ax1.set_title('Strong Scaling Analysis')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Weak Scaling\n",
        "    ax2 = plt.subplot(2, 3, 2)\n",
        "    p_values = [1, 4, 16, 64]\n",
        "    problem_sizes = [10000, 40000, 160000, 640000]  # Aumenta con p\n",
        "\n",
        "    efficiencies = []\n",
        "    for p, N in zip(p_values, problem_sizes):\n",
        "        model = ParallelPerformanceModel(N, p)\n",
        "        efficiencies.append(model.compute_efficiency())\n",
        "\n",
        "    ax2.bar(range(len(p_values)), efficiencies, color=['blue', 'green', 'orange', 'red'])\n",
        "    ax2.set_xticks(range(len(p_values)))\n",
        "    ax2.set_xticklabels([f'p={p}\\nN={int(np.sqrt(N))}' for p, N in zip(p_values, problem_sizes)])\n",
        "    ax2.set_ylabel('Efficiency')\n",
        "    ax2.set_title('Weak Scaling Analysis')\n",
        "    ax2.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # 3. Kiviat Diagram for Performance Metrics\n",
        "    ax3 = plt.subplot(2, 3, 3, projection='polar')\n",
        "\n",
        "    metrics = ['Speedup', 'Efficiency', 'Scalability', 'Load Balance', 'Comm/Comp Ratio']\n",
        "    values = [0.7, 0.65, 0.8, 0.9, 0.3]  # Valores de ejemplo normalizados\n",
        "\n",
        "    angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()\n",
        "    values += values[:1]\n",
        "    angles += angles[:1]\n",
        "\n",
        "    ax3.plot(angles, values, 'o-', linewidth=2)\n",
        "    ax3.fill(angles, values, alpha=0.25)\n",
        "    ax3.set_xticks(angles[:-1])\n",
        "    ax3.set_xticklabels(metrics)\n",
        "    ax3.set_title('Performance Metrics Radar Chart', pad=20)\n",
        "\n",
        "    # 4. Communication/Computation Ratio\n",
        "    ax4 = plt.subplot(2, 3, 4)\n",
        "\n",
        "    p_values = np.logspace(0, 2, 20)\n",
        "    ratios = []\n",
        "\n",
        "    for p in p_values:\n",
        "        model = ParallelPerformanceModel(10000, int(p))\n",
        "        comp = model.compute_serial_time() / p\n",
        "        # Estimación simplificada de comunicación\n",
        "        N_local = 100 / np.sqrt(p)\n",
        "        comm = 4 * N_local * 8 * model.beta\n",
        "        ratios.append(comm / comp if comp > 0 else 0)\n",
        "\n",
        "    ax4.semilogx(p_values, ratios, 'g-', linewidth=2)\n",
        "    ax4.axhline(y=1.0, color='r', linestyle='--', label='Comm = Comp')\n",
        "    ax4.set_xlabel('Number of Processes (log scale)')\n",
        "    ax4.set_ylabel('Communication / Computation Ratio')\n",
        "    ax4.set_title('Comm/Comp Ratio vs Processes')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Iso-efficiency Analysis\n",
        "    ax5 = plt.subplot(2, 3, 5)\n",
        "\n",
        "    p = np.arange(1, 65)\n",
        "    # W = K * p * Tp, donde W es trabajo, Tp es tiempo paralelo\n",
        "    iso_efficiency = p / (1 + 0.01 * np.sqrt(p))  # Ejemplo simplificado\n",
        "\n",
        "    ax5.plot(p, iso_efficiency, 'purple', linewidth=2)\n",
        "    ax5.set_xlabel('Number of Processes')\n",
        "    ax5.set_ylabel('Problem Size (Normalized)')\n",
        "    ax5.set_title('Iso-efficiency Function')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Performance Model Comparison\n",
        "    ax6 = plt.subplot(2, 3, 6)\n",
        "\n",
        "    p = np.arange(1, 65)\n",
        "\n",
        "    # Diferentes modelos\n",
        "    amdahl = 1 / (0.05 + 0.95/p)  # 5% serial\n",
        "    gustafson = 0.05 + 0.95*p     # 5% serial\n",
        "    real = p / (1 + 0.1*np.log2(p) + 0.01*np.sqrt(p))  # Modelo realista\n",
        "\n",
        "    ax6.plot(p, p, 'k--', label='Ideal', alpha=0.5)\n",
        "    ax6.plot(p, amdahl, 'r-', label=\"Amdahl's Law\", linewidth=2)\n",
        "    ax6.plot(p, gustafson, 'g-', label=\"Gustafson's Law\", linewidth=2)\n",
        "    ax6.plot(p, real, 'b-', label='Realistic Model', linewidth=2)\n",
        "    ax6.set_xlabel('Number of Processes')\n",
        "    ax6.set_ylabel('Speedup')\n",
        "    ax6.set_title('Performance Models Comparison')\n",
        "    ax6.legend()\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Complete Parallel Performance Analysis for Heat Equation', fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('performance_analysis_complete.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def generate_performance_report():\n",
        "    \"\"\"Genera reporte detallado de performance\"\"\"\n",
        "\n",
        "    report = \"\"\"\n",
        "    ========================================================\n",
        "    PERFORMANCE ANALYSIS REPORT: 2D HEAT EQUATION SOLVER\n",
        "    ========================================================\n",
        "\n",
        "    1. ALGORITHM OVERVIEW\n",
        "    ---------------------\n",
        "    Algorithm: Jacobi iteration for 2D heat equation\n",
        "    Parallel Model: SPMD with domain decomposition\n",
        "    Communication: MPI point-to-point (halo exchange) + collective operations\n",
        "\n",
        "    2. SEQUENCE OF OPERATIONS (per iteration):\n",
        "    ------------------------------------------\n",
        "    Step 1: Halo Communication (non-blocking)\n",
        "            - MPI_Isend/MPI_Irecv for 4 directions\n",
        "            - MPI_Waitall for synchronization\n",
        "\n",
        "    Step 2: Local Computation\n",
        "            - Finite difference calculation\n",
        "            - Local max difference computation\n",
        "\n",
        "    Step 3: Global Synchronization (every 'stride' iterations)\n",
        "            - MPI_Allreduce for global max\n",
        "            - Convergence check\n",
        "\n",
        "    Step 4: Update local values\n",
        "\n",
        "    3. COMPLEXITY ANALYSIS:\n",
        "    -----------------------\n",
        "    a) Computation per iteration: O(N²/p) flops\n",
        "    b) Communication per iteration: O(√(N²/p)) bytes\n",
        "    c) Synchronization: O(log p) every 'stride' iterations\n",
        "\n",
        "    4. SCALABILITY ASSESSMENT:\n",
        "    --------------------------\n",
        "    Strong Scaling Limit: Limited by communication overhead\n",
        "    Weak Scaling Efficiency: Good for balanced domain decomposition\n",
        "    Bottlenecks: Halo communication and global reductions\n",
        "\n",
        "    5. OPTIMIZATION RECOMMENDATIONS:\n",
        "    --------------------------------\n",
        "    1. Use MPI_Neighbor_alltoall for structured grids\n",
        "    2. Implement communication-computation overlap\n",
        "    3. Adjust 'stride' parameter based on problem size\n",
        "    4. Consider asynchronous iteration methods\n",
        "\n",
        "    6. EXPECTED PERFORMANCE METRICS:\n",
        "    ---------------------------------\n",
        "    Metric                  | Good       | Fair       | Poor\n",
        "    -------------------------------------------------------\n",
        "    Parallel Efficiency     | > 70%      | 40-70%     | < 40%\n",
        "    Comm/Comp Ratio        | < 0.1      | 0.1-0.3    | > 0.3\n",
        "    Load Imbalance         | < 5%       | 5-15%      | > 15%\n",
        "\n",
        "    ========================================================\n",
        "    \"\"\"\n",
        "\n",
        "    with open('performance_report.txt', 'w') as f:\n",
        "        f.write(report)\n",
        "\n",
        "    print(report)\n",
        "\n",
        "# Ejecutar análisis completo\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Iniciando análisis de performance...\")\n",
        "\n",
        "    # 1. Análisis de patrones de comunicación\n",
        "    df_comm = analyze_communication_pattern()\n",
        "    print(\"Análisis de comunicación:\")\n",
        "    print(df_comm.to_string())\n",
        "\n",
        "    # 2. Generar gráficos de escalabilidad\n",
        "    plot_scalability_analysis()\n",
        "\n",
        "    # 3. Generar reporte\n",
        "    generate_performance_report()\n",
        "\n",
        "    # 4. Modelo de performance para diferentes configuraciones\n",
        "    print(\"\\nModelo de performance para diferentes configuraciones:\")\n",
        "    configs = [\n",
        "        (10000, 1),\n",
        "        (10000, 4),\n",
        "        (10000, 16),\n",
        "        (10000, 64)\n",
        "    ]\n",
        "\n",
        "    for N, p in configs:\n",
        "        model = ParallelPerformanceModel(N, p)\n",
        "        print(f\"\\nN={N}, p={p}:\")\n",
        "        print(f\"  Speedup teórico: {model.compute_speedup():.2f}\")\n",
        "        print(f\"  Eficiencia teórica: {model.compute_efficiency():.2%}\")\n",
        "\n",
        "    print(\"\\nAnálisis completado. Archivos generados:\")\n",
        "    print(\"1. performance_analysis_complete.png\")\n",
        "    print(\"2. performance_report.txt\")\n",
        "    print(\"3. communication_analysis.csv\")"
      ],
      "metadata": {
        "id": "G0nCHmLf5DED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}